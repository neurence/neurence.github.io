<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Catchup 20230818</title>
    <style>
        body {
            font-family: sans-serif;
        }

        div {
            margin: 20px;
        }

        div.section {
            background: #c7e3ff;
            padding: 10px;
        }

        div.center {
            text-align: center;
        }
        #older {
            display: none;
        }
        #older:target {
            display: block;
        }

        table {
            font-size: small;
            background: #88c0e3;
            padding: 10px;
        }
    </style>
</head>
<body>
<div>
    <h1>Current Audio Work</h1>
    <div class="section">
        <h2>Streaming Low-latency Decoder</h2>

        <p>Previously, we've done minimal modifications to the architectures of the encoder and decoder networks.</p>
        <p>We've done just enough to  repurpose the decoder (which was designed as a mel-to-audio converter) to handle transformer features rather than mel-spectrograms:</p>
        <div class="center"><img src="media/img/hifi-gan-1.png" width="745"></div>

        <p>To make the pipeline work for realtime streaming we're digging deeper into the network architectures and making more significant changes:</p>
        <p>Each convolution and addition in the network requires a causal buffer of historical input.  Before summing or passing to downstream layers, the introduced delay needs to be accounted for. </p>
        <p>With the current architecture, this leads to a total latency of about 50 ms.</p>
        <p>Below is a model graph showing a single residual block, which uses thirty causal buffers (not shown).  There are four of these blocks in the model.</p>
        <div class="center"><img src="media/img/hifi-gan-resnet-detail.png" width="640"></div>
        <p>The conversion to realtime streaming is still in progress. Here is some audio output from the partially converted network, trained on clean mel-spectrograms,  with a frame (audio buffer) size of 1536 samples:</p>
        <table>
            <thead>
            <tr>
                <th>Frame Size 1536, Non-causal<br />(unmodified network)</th>
                <th>Frame Size 1536, Causal<br />(modified network)</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td><audio controls src="media/streaming/no_window.wav"></audio></td>
                <td><audio controls src="media/streaming/valid_male_clean_020.22k_causal_generated.wav"></audio></td>
            </tr>
            </tbody>
        </table>

    </div>

    <div class="section">
        <h2>Porting The Encoder to a Mobile Device</h2>

        <p>To prepare for adding the transformer encoder to a streaming pipeline, we've exported the HuBERT transformer network into both CoreML and ONNX formats, checking output precision and processing times. One of the versions of the encoder network we are currently working with is hubert-large-ll60k, which has hidden size of 1024, 16 attention heads and 24 hidden layers contributing to ~316M parameters.</p>
        <div class="center"><img src="media/img/hubert_mlmodel_screenshot_fp16.png" width="915"></div>
        <p>We're testing on an iPhone 14 Pro for compatibility, and for performance of the different compute units (CPU, GPU and Neural Engine). There is an issue with on device processing using the Neural Engine, which is still being investigated. Currently, we're investigating how to process the smaller frame sizes without loss of output quality arising from the smaller receptive field size.</p>
        <table>
            <tr>
                <th>Frame Time (secs)&nbsp;&nbsp;</th>
                <th>Compute Unit&nbsp;&nbsp;</th>
                <th>Precision&nbsp;&nbsp;</th>
                <th>Processing Time (secs)&nbsp;&nbsp;</th>
            </tr>
            <tr>
                <td>1</td>
                <td>CPU</td>
                <td>fp32</td>
                <td>0.613</td>
            </tr>
            <tr>
                <td>1</td>
                <td>CPU</td>
                <td>fp16</td>
                <td>0.285</td>
            </tr>
            <tr>
                <td>1</td>
                <td>CPU&GPU</td>
                <td>fp16</td>
                <td>0.267</td>
            </tr>
            <tr>
                <td>0.02</td>
                <td>CPU</td>
                <td>fp32</td>
                <td>0.0842</td>
            </tr>
            <tr>
                <td>0.02</td>
                <td>CPU</td>
                <td>fp16</td>
                <td>0.119</td>
            </tr>
            <tr>
                <td>0.02</td>
                <td>CPU&GPU</td>
                <td>fp32</td>
                <td>0.0834</td>
            </tr>
        </table>
    </div>

    <h1>Targets for next week:</h1>
    <ul>
        <li>Porting the Decoder to a mobile device</li>
        <li>Training the modified Decoder network from scratch using the full denoising pipeline</li>
    </ul>
    <hr/>
    <div>
        Recent catch-ups:
        <a href="index_20230811.html">2023-08-11</a>
        <a href="index_20230804.html">2023-08-04</a>
    </div>
    <div>
        <a href="#older">Older catch-ups:</a>
        <div id="older">
            <a href="index_20230728.html">2023-07-28</a>
            <a href="index_20230721.html">2023-07-21</a>
            <a href="index_20230714.html">2023-07-14</a>
            <a href="index_20230707.html">2023-07-07</a>
            <a href="index_20230630.html">2023-06-30</a>
            <a href="index_20230623.html">2023-06-23</a>
            <a href="index_20230616.html">2023-06-16</a>
            <a href="index_20230609.html">2023-06-09</a>
            <a href="index_20230602.html">2023-06-02</a>
            <a href="index_20230526.html">2023-05-26</a>
            <a href="#">(Hide)</a>
        </div>
    </div>
</div>
</body>
</html>
