<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Catchup 20231006</title>
    <style>
        body {
            font-family: sans-serif;
        }

        div {
            margin: 20px;
        }

        div.section {
            background: #c7e3ff;
            padding: 10px;
        }

        div.center {
            text-align: center;
        }
        #older {
            display: none;
        }
        #older:target {
            display: block;
        }

        table {
            font-size: small;
            background: #88c0e3;
            padding: 10px;
        }

        .num {
            text-align: right;
            border: 1px solid gray;
        }

        .bad {
            color: red;
        }
        th.highlight {}

    </style>
</head>
<body>
<div>
    <div class="section">
        <h2>iOS Test App autoencoder benchmarks and analysis</h2>
        <p>Here are the processing timings for the iOS test application using non-causal encoder and causal decoder on an iPhone 11 Pro.</p>
        <p>The first set of timings use a 16000 sample (1s) input buffer for the autoencoder.</p>
        <p>The second set of timings are for a 6400 sample (0.4s) buffer.</p>
        <p>The third set of timings are for a 3200 sample (0.2s) buffer.</p>
        <p>All the timings are averaged over 1 minute.</p>

        <table>
            <thead>
            <tr>
                <th>Input Size (samps)</th>
                <th>Encoder Time (ms)</th>
                <th>Decoder Time (ms)</th>
                <th>Total autoencoding time</th>
                <th>X realtime<br/>(> 1 means faster than realtime)</th>
            </tr>
            </thead>
            <tbody>
            <img>
            <tr>
                <td class="num">16000</td>
                <td class="num">407.8</td>
                <td class="num">157.7</td>
                <td class="num">565.5</td>
                <td class="num">1.768</td>
            </tr>
            <tr>
                <td class="num">6400</td>
                <td class="num">204.7</td>
                <td class="num">98.8</td>
                <td class="num">303.5</td>
                <td class="num">1.318</td>
            </tr>
            <tr>
                <td class="num">3200</td>
                <td class="num">193.9</td>
                <td class="num">27.0</td>
                <td class="num">220.9</td>
                <td class="num bad">.905</td>
            </tr>
            </tbody>
        </table>
        <div>
            <img src="media/img/AutoencoderTiming.png">
        </div>

        <p>Here is a recording using denoiser and autoencoder with one second input length:</p>
        <p>Input</p>
        <audio controls src="media/test_ios_app_io/recordingInput_220923_123901.wav"></audio>
        <p>Output</p>
        <audio controls src="media/test_ios_app_io/recording_220923_123901.wav"></audio>
    </div>
    <div class="section">
        <h2>Low-latency autoencoder work</h2>
        <p>We've begin work on latency reduction in the encoder (Hubert/Wav2Vec2) network.  This is a large and complex network, but basically consists of two modules:</p>
        <ul>
            <li>A latent feature encoder;</li>
            <li>A content transformer</li>
        </ul>
        <p>The latent feature encoder is a relatively straightforward convolutional network, which transforms blocks of audio into feature "frames". It adds some (~50 ms) latency to the network, and is non-causal in its design. As an initial step, we're transforming this into a fully causal network.</p>
        <p>The content transformer is non-streaming in its design, and significant structural changes are required to make it effectively streamable with low latency.</p>
        <p>This is being done in three stages:</p>
        <ul>
            <li>The first stage is simply to feed overlapped windowed frames into the network.  It will do unnecessary work "recalculating" the overlapped segments, but, providing processing power is sufficient, this will lower its latency. </li>
            <li>The second stage is to reduce acausality by shifting the window center, reducing the number of "lookahead" frames relative to past frames. This will be the main focus of the latency reduction task next week.</li>
            <li>The third stage is to remove the latency further by converting the attention blocks to "LLSA" blocks, which calculate multiple shifted outputs, which provide  lookahead results for downstream attention blocks.  .</li>

        </ul>
        <p>The figures below show the above "streamifying" stages.</p>
        <figure>
            <img src="media/img/2302_1.jpg" width="1024">
            <figcaption><strong>Acausal attention</strong></figcaption>
        </figure>
        <figure>
            <img src="media/img/2302_2.jpg" width="1024">
            <figcaption><strong>Streaming attention</strong></figcaption>
        </figure>
        <figure>
            <img src="media/img/2302_3.jpg" width="1024">
            <figcaption><strong>Low-Latency Streaming attention (LLSA)</strong></figcaption>
        </figure>

    </div>
    <div class="section">
        <h2>Latent feature prediction</h2>

        <p>Our goal here is to take encoded (non-causal) audio features and, using a simple neural network, estimate features at a later point in time. </p>
        <p>We are not actually predicting the future, but rather extracting information we know to be encoded in the features from a short time ahead of their nominal time step. </p>
        <p>Features therefore become available to the decoder earlier, thus reducing latency at a cost of the loss of some accuracy.</p>
        <p>The assumption is that due to the limits of human speech, the features themselves should be smooth and have low magnitude gradients w.r.t. time.</p>
        <p>New features are generated by predicting a residual from the latest available feature vector. </p>


        <table>

            <tbody>
            <tr><td colspan="3"><h3>Original feature frames (target)</h3></td></tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/original/gen0.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/original/gen1.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/original/gen3.wav"></audio>
                </td>
            </tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/original/gen5.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/original/gen7.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/original/gen10.wav"></audio>
                </td>
            </tr>

            </tbody>
            </thead>
            <tbody>
            <tr><td colspan="3"><h3>test_1_n1    - Predict next frame from current frame (look ahead 20ms)</h3></td></tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_1_n1_10000/eval/pred0.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_1_n1_10000/eval/pred1.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_1_n1_10000/eval/pred3.wav"></audio>
                </td>
            </tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_1_n1_10000/eval/pred5.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_1_n1_10000/eval/pred7.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_1_n1_10000/eval/pred10.wav"></audio>
                </td>
            </tr>

            </tbody>

            <tbody>
            <tr><td colspan="3"><h3>test_2_n6    - Predict frame + 6 indirectly, by framewise prediction (look ahead 120ms)</h3></td></tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n6_11000/eval/pred0.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n6_11000/eval/pred1.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n6_11000/eval/pred3.wav"></audio>
                </td>
            </tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n6_11000/eval/pred5.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n6_11000/eval/pred7.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n6_11000/eval/pred10.wav"></audio>
                </td>
            </tr>

            </tbody>
            </thead>
            <tbody>
            <tr><td colspan="3"><h3>test_2_n9    - Predict frame + 9 indirectly, by framewise prediction (look ahead 180ms). <br>This is about the limit of recognisable speech, after which it becomes unstructured babble.</h3></td></tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n9_592000/eval/pred0.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n9_592000/eval/pred1.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n9_592000/eval/pred3.wav"></audio>
                </td>
            </tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n9_592000/eval/pred5.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n9_592000/eval/pred7.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_2_n9_592000/eval/pred10.wav"></audio>
                </td>
            </tr>

            </tbody>
            </thead>
            <thead>
            <tr><td colspan="3"><h3>test_5_m3_n3    - Predict frame + 3 based on previous 3 frames (look ahead 60ms)</h3></td></tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m3_n3_25000/eval/pred0.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m3_n3_25000/eval/pred1.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m3_n3_25000/eval/pred3.wav"></audio>
                </td>
            </tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m3_n3_25000/eval/pred5.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m3_n3_25000/eval/pred7.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m3_n3_25000/eval/pred10.wav"></audio>
                </td>
            </tr>

            </tr>
            </thead>
            <thead>
            <tr><td colspan="3"><h3>test_5_m4_n4    - Predict frame + 4 based on previous 4 frames (look ahead 80ms)</h3></td></tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m4_n4_23000/eval/pred0.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m4_n4_23000/eval/pred1.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m4_n4_23000/eval/pred3.wav"></audio>
                </td>
            </tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m4_n4_23000/eval/pred5.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m4_n4_23000/eval/pred7.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m4_n4_23000/eval/pred10.wav"></audio>
                </td>
            </tr>

            </tr>
            </thead>
            <tbody>
            <tr><td colspan="3"><h3>test_5_m5_n5    - Predict frame + 5 based on previous 5 frames (look ahead 100ms)</h3></td></tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m5_n5_10000/eval/pred0.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m5_n5_10000/eval/pred1.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m5_n5_10000/eval/pred3.wav"></audio>
                </td>
            </tr>
            <tr>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m5_n5_10000/eval/pred5.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m5_n5_10000/eval/pred7.wav"></audio>
                </td>
                <td>
                    <audio controls src="media/feature_prediction/test_5_m5_n5_10000/eval/pred10.wav"></audio>
                </td>
            </tr>

            </tbody>
        </table>

    </div>
    <hr/>

    <div>
        Recent catch-ups:
        <a href="index_20230922.html">2023-09-22</a>
        <a href="index_20230908.html">2023-09-08</a>
        <a href="index_20230825.html">2023-08-25</a>

    </div>
    <div>
        <a href="#older">Older catch-ups:</a>
        <div id="older">
            <a href="index_20230818.html">2023-08-18</a>
            <a href="index_20230811.html">2023-08-11</a>
            <a href="index_20230804.html">2023-08-04</a>
            <a href="index_20230728.html">2023-07-28</a>
            <a href="index_20230721.html">2023-07-21</a>
            <a href="index_20230714.html">2023-07-14</a>
            <a href="index_20230707.html">2023-07-07</a>
            <a href="index_20230630.html">2023-06-30</a>
            <a href="index_20230623.html">2023-06-23</a>
            <a href="index_20230616.html">2023-06-16</a>
            <a href="index_20230609.html">2023-06-09</a>
            <a href="index_20230602.html">2023-06-02</a>
            <a href="index_20230526.html">2023-05-26</a>
            <a href="#">(Hide)</a>
        </div>
    </div>
</div>
</body>
</html>
