<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Catchup 20231013</title>
    <style>
        body {
            font-family: sans-serif;
        }

        div {
            margin: 20px;
        }

        div.section {
            background: #c7e3ff;
            padding: 10px;
        }

        div.center {
            text-align: center;
        }
        #older {
            display: none;
        }
        #older:target {
            display: block;
        }

        table {
            font-size: small;
            background: #88c0e3;
            padding: 10px;
        }

        .num {
            text-align: right;
            border: 1px solid gray;
        }
        .bordered {
            border: 1px solid gray;
        }

        .bad {
            font-weight: bold;
            color: red;
        }
        .good {
            font-weight: bold;
            color: #035d03;
        }
        th.highlight {}

    </style>
</head>
<body>
<div>
    <div class="section">
        <h2>iOS autoencoder Latency Reduction</h2>
        <a>We've implemented a short-buffer autoencoder on the iPhone which can utilize  the high-end iPhone's A11 neural engine. This has led to significant speed improvements.</a>
        <p>Here are the processing timings for the iOS test application using non-causal encoder and non-causal decoder on an iPhone 15 Pro and iPhone 11 Pro.</p>
        <p>The timings are for a 3200 sample buffer (200ms).</p>
        <p>Based on the results of our earlier experiments, block sizes below 3200 degrade the output  due to its inherent latency (of around 200ms @ 16k)</p>

        <table>
            <thead>
            <tr>
                <th>Device</th>
                <th>Compute Backend</th>
                <th>Encoder Time (ms)</th>
                <th>Decoder Time (ms)</th>
                <th>Total autoencoding time</th>
                <th>X realtime<br/>(> 1 means faster than realtime)</th>
            </tr>
            </thead>
            <tbody>

            <tr>
                <td class="bordered">iPhone 11 Pro</td>
                <td class="bordered">CPU</td>
                <td class="num">193.9</td>
                <td class="num">27.0</td>
                <td class="num">220.9</td>
                <td class="num bad">.905</td>
            </tr>
            <tr>
                <td class="bordered">iPhone 15 Pro</td>
                <td class="bordered">CPU</td>
                <td class="num">71.2</td>
                <td class="num">8.4</td>
                <td class="num">88.3</td>
                <td class="num good">2.26</td>
            </tr>
            <tr>
                <td class="bordered">iPhone 15 Pro</td>
                <td class="bordered">CPU+GPU</td>
                <td class="num">74.3</td>
                <td class="num">14.3</td>
                <td class="num">97.3</td>
                <td class="num good">2.05</td>
            </tr>
            <tr>
                <td class="bordered">iPhone 15 Pro</td>
                <td class="bordered">CPU+NEURAL ENGINE</td>
                <td class="num">26.4</td>
                <td class="num">11.8</td>
                <td class="num">71.5</td>
                <td class="num good">2.80</td>
            </tr>
            </tbody>
        </table>
        <p>The above results mean that, for a high-end iPhone, latency reduction can be achieved by
            <strong>frame-overlapping</strong>.  Taking the best-performing case, where the both CPU and the built-in A11 neural engine are used, neural network latency can be more reduced by well over 50% to under 100ms.  This is our current work on latency reduction.</p>
        <p> </p>

    </div>
    <div class="section">
        <h2>Low-latency Encoder</h2>
         <p>The encoder is non-streaming in its design, and significant structural changes are required to make it effectively streamable with low latency.</p>
        <p>This is being done in three stages:</p>
        <ul>
            <li>The first stage (currently in progress) is simply to feed overlapped windowed frames into the network.  It will do unnecessary work "recalculating" the overlapped segments, but, providing processing power is sufficient, this will lower its latency. </li>
            <li>The second stage is to reduce acausality by shifting the window center, reducing the number of "lookahead" frames relative to past frames. This will be the main focus of the latency reduction task next week.</li>
            <li>The third stage is to remove the latency further by converting the attention blocks to "LLSA" blocks, which calculate multiple shifted outputs, which provide  lookahead results for downstream attention blocks.  .</li>

        </ul>

    </div>
    <hr/>

    <div>
        Recent catch-ups:
        <a href="index_20231006.html">2023-10-06</a>
        <a href="index_20230922.html">2023-09-22</a>
        <a href="index_20230908.html">2023-09-08</a>
        <a href="index_20230825.html">2023-08-25</a>

    </div>
    <div>
        <a href="#older">Older catch-ups:</a>
        <div id="older">
            <a href="index_20230818.html">2023-08-18</a>
            <a href="index_20230811.html">2023-08-11</a>
            <a href="index_20230804.html">2023-08-04</a>
            <a href="index_20230728.html">2023-07-28</a>
            <a href="index_20230721.html">2023-07-21</a>
            <a href="index_20230714.html">2023-07-14</a>
            <a href="index_20230707.html">2023-07-07</a>
            <a href="index_20230630.html">2023-06-30</a>
            <a href="index_20230623.html">2023-06-23</a>
            <a href="index_20230616.html">2023-06-16</a>
            <a href="index_20230609.html">2023-06-09</a>
            <a href="index_20230602.html">2023-06-02</a>
            <a href="index_20230526.html">2023-05-26</a>
            <a href="#">(Hide)</a>
        </div>
    </div>
</div>
</body>
</html>
