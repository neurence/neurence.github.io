<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Catchup 20230714</title>
    <style>
        body {
            font-family: sans-serif;
        }

        div {
            margin: 20px;
        }

        div.section {
            background: #c7e3ff;
            padding: 10px;
        }
        table {
            font-size: small;
            background: #88c0e3;
            padding: 10px;
        }
    </style>
</head>
<body>
<div>
    <h1>Current Audio Work</h1>
    <div  class="section">

        <h2>Autoencoder Experiments</h2>
        <p>The table below compares various autoencoder ("wav2vec2wav") models' performance on bar noise conversations.</p>
            <table>
                <thead>
                <tr>
                    <th>Original/Denoised</th><th>HuBERT-Large</th><th>HuBERT-Large+Emb</th><th>WavLM-Base+Emb</th><th>WavLM-Large+SE</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td>
                        <div> <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample1_050723_185337/noisy.wav"></audio></div>
                        <div><audio controls src="media/cambridge_pub_recordings/pub_recordings/sample1_050723_185337/denoised.wav"></audio></div>

                    </td>

                    <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample1_050723_185337/hubert_large_denoised.wav"></audio>
                    </td>
                    <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample1_050723_185337/hubert_large_emb_denoised.wav"></audio>

                    </td>
                    <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample1_050723_185337/wavlm_base_emb_denoised.wav"></audio>
                    </td>
                    <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample1_050723_185337/freevc_denoised.wav"></audio>
                    </td>
                </tr>
                <tr>
                     <td>
                        <div> <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/noisy.wav"></audio></div>
                        <div><audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/denoised.wav"></audio></div>

                    </td>
                    <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/hubert_large_denoised.wav"></audio>
                    </td>
                    <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/hubert_large_emb_denoised.wav"></audio>
                    </td>
                    <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/wavlm_base_emb_denoised.wav"></audio>
                    </td>
                                        <td>
                     <audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/freevc_denoised.wav"></audio>
                    </td>
                </tr>
                </tbody>
            </table>

        <div>
            <h3>Models Used:</h3>
            <ul>
                <li><p><strong>HuBERT-Large:</strong><br/>The large model HuBERT transformer network, HifiGAN decoder</p></li>
                <li><p><strong>HuBERT-Large+Emb:</strong><br/>The large model HuBERT transformer network, with simple speaker embedding, HifiGAN decoder</p></li>
                <li><p><strong>WavLM-Base+Emb:</strong><br/>The base (small) model <a href="https://arxiv.org/abs/2110.13900">WavLM</a> transformer network, with simple speaker embedding, HifiGAN decoder</p></li>
                <li><p><strong>WavLM-Large+SE:</strong><br/>The large model <a href="https://arxiv.org/abs/2110.13900">WavLM</a> transformer network, with LSTM-based speaker encoder, HifiGAN decoder.<br/>This pipleine is based on the <a href="https://arxiv.org/abs/2210.15418">FreeVC</a> one-shot voice conversion network.</p></li>
           </ul>

        </div>
    </div>
        <div class="section">
        <h2>Multiple speakers</h2>

        <p>When multiple speakers are present, the wrong speaker might be synthesised.</p>
            <p>To illustrate this, below is the WavLM-Large+SE output from the second audio sample above (when Deborah and Josh are speaking), with Josh's voice first included, and then removed from the source audio.</p>
<table>
    <thead><tr><th>Multiple Speakers</th><th>Single Speaker</th></tr></thead>
    <tbody><tr><td><audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/freevc_denoised_trunc_10_seconds.wav"></audio></td><td><audio controls src="media/cambridge_pub_recordings/pub_recordings/sample2_050723_183053/freevc_denoised_first_10_seconds.wav"></audio></td></tr></tbody>
    <p>This issue can be addressed by reducing the receptive field for the speaker encoder, making it less likely to include more than one speaker.</p>

</table>
    </div>

    <hr/>
    <div>
        Previous catch-ups:
        <a href="index_20230707.html">2023-07-07</a>
        <a href="index_20230630.html">2023-06-30</a>
        <a href="index_20230623.html">2023-06-23</a>
        <a href="index_20230616.html">2023-06-16</a>
        <a href="index_20230609.html">2023-06-09</a>
        <a href="index_20230602.html">2023-06-02</a>
        <a href="index_20230526.html">2023-05-26</a>
    </div>
</div>
</body>
</html>
